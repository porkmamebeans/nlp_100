{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1章：準備運動\n",
    "========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00. 文字列の逆襲\n",
    "--------------\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'stressed'[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. 「パタトクカシーー」\n",
    "--------------------\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'パタトクカシーー'[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "------\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "y = \"\"\n",
    "for x in range(4):\n",
    "    y += 'パトカー'[x]+'タクシー'[x]\n",
    "    x += 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03. 円周率\n",
    "-----\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "s = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "s = s.replace(',', '')\n",
    "s = s.replace('.', '')\n",
    "s = s.split()\n",
    "arr = []\n",
    "for i in range(len(s)):\n",
    "    arr.append(len(s[i]))\n",
    "    \n",
    "print(len(s) == len(arr))\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04. 元素記号\n",
    "-----------\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "s = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "s = s.replace('.', '')\n",
    "s = s.replace(',', '')\n",
    "s = s.split()\n",
    "thisDict = {}\n",
    "for i in range(0, len(s)):\n",
    "    if(i == 0 or i == 4 or i == 5 or i == 6 or i == 7 or i == 8 or i == 14 or i == 15 or i == 18):\n",
    "        thisDict[s[i][0]] = i+1\n",
    "    else:\n",
    "        thisDict[s[i][0] + s[i][1]] = i+1\n",
    "print(thisDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05. n-gram\n",
    "-----\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am', 'am an', 'an NLPer']\n",
      "['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def n_gram(sentence, n, case):\n",
    "    # tokenise the sentence by removing the space\n",
    "    token = [token for token in sentence.split(\" \") if token != \"\"]\n",
    "    # split the sentence into its chars\n",
    "    char = [char for char in sentence if char !=\" \"]\n",
    "    if case == 0:\n",
    "        # unite n tokens together in one zip\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        # join the elements in zips with space in between\n",
    "        return(list(\" \".join(ngram) for ngram in ngrams))\n",
    "    if case == 1:\n",
    "        ngrams = zip(*[char[i:] for i in range(n)])\n",
    "        return(list(\"\".join(ngram) for ngram in ngrams))\n",
    "def char_n_gram(sentence, n):\n",
    "    char = [char for char in sentence if char != \" \"]\n",
    "    ngrams = zip(*[char[i:] for i in range(n)])\n",
    "    return(\"\".join(ngram) for ngram in ngrams)\n",
    "\n",
    "sentence = \"I am an NLPer\"\n",
    "wbg = n_gram(sentence, 2, 0)\n",
    "cbg = n_gram(sentence, 2, 1)\n",
    "\n",
    "print(wbg)\n",
    "print(cbg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06. 集合\n",
    "----\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is', 'ap', 'ar', 'se', 'di', 'ph', 'gr', 'ra', 'ag', 'ad', 'pa'} {'ar', 'ap', 'ra', 'pa'} {'is', 'se', 'di', 'ad'}\n",
      "'se' is contained in X\n"
     ]
    }
   ],
   "source": [
    "X = n_gram(\"paraparaparadise\", 2, 1)\n",
    "Y = n_gram(\"paragraph\", 2, 1)\n",
    "# List Union\n",
    "U = set(X).union(Y)\n",
    "# List Intersect\n",
    "I = set(X).intersection(Y)\n",
    "# List Difference\n",
    "D = set(X).difference(Y)\n",
    "print(U, I, D)\n",
    "if 'se' in X and 'se' in Y:\n",
    "    print(\"'se' is contained in X and Y\")\n",
    "elif 'se' in X:\n",
    "    print(\"'se' is contained in X\")\n",
    "elif 'se' in Y:\n",
    "    print(\"'se' is contained in Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07. テンプレートによる文生成\n",
    "----\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template(x, y, z):\n",
    "    print(str(x) + \"時の\" + str(y) + \"は\" + str(z))\n",
    "template(12, \"気温\", 22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08. 暗号文\n",
    "---\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "英小文字ならば(219 - 文字コード)の文字に置換\n",
    "その他の文字はそのまま出力\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha\n"
     ]
    }
   ],
   "source": [
    "def cipher(sentence):\n",
    "    sentenceList = []\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i].islower():\n",
    "            sentenceList.insert(i, chr(219 - ord(sentence[i])))\n",
    "        else:\n",
    "            sentenceList.insert(i, sentence[i])\n",
    "    print(\"\".join(sentenceList))\n",
    "cipher(\"Aoksz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09. Typoglycemia\n",
    "---\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sentence = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "def randomise(sentence):\n",
    "    sentence = sentence.split(\" \")\n",
    "    for word in sentence:\n",
    "        if len(word) > 4:\n",
    "            _word = list(word[1:-1])\n",
    "            random.shuffle(_word)\n",
    "            word = word[0] + \"\".join(_word) + word[-1]\n",
    "            return(word)\n",
    "        else:\n",
    "            return(word)   \n",
    "randomise(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
